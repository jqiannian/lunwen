# ç®—æ³•è®¾è®¡æ–¹æ¡ˆï¼ˆITER-2025-01 ç»†åŒ–ç‰ˆï¼‰

## å…ƒæ•°æ®
| å­—æ®µ | å†…å®¹ |
| --- | --- |
| æ–‡æ¡£ç‰ˆæœ¬ | v2.0ï¼ˆæ–¹æ¡ˆ1ç³»ç»Ÿæ€§é‡æ„åï¼‰ |
| åŸç‰ˆæœ¬ | v1.0ï¼ˆå­˜åœ¨è®¾è®¡é—®é¢˜ï¼‰ |
| è¿­ä»£ç¼–å· | ITER-2025-01 |
| åˆ›å»ºæ—¶é—´ | 2025-12-03 |
| è´£ä»»äºº | ç®—æ³•æ¶æ„å¸ˆ |
| çŠ¶æ€ | âœ… é‡æ„å®Œæˆï¼ˆæ–¹æ¡ˆ1å·²å®Œå–„ï¼‰ |
| å…³è”æ–‡æ¡£ | `Design-ITER-2025-01.md` v2.0, `Requirement-ITER-2025-01.md` |
| é‡æ„è¿½è¸ª | `DESIGN_REFACTOR_TRACKER.md` |

## æ–‡æ¡£ç›®çš„
é’ˆå¯¹"çº¢ç¯åœæ— ç›‘ç£å¼‚å¸¸æ£€æµ‹"åœºæ™¯ï¼Œæä¾›**3ç§æŠ€æœ¯è·¯çº¿**çš„å®Œæ•´ç®—æ³•è®¾è®¡ï¼ŒåŒ…æ‹¬ï¼š
- æ•°å­¦æ¨¡å‹ä¸å…¬å¼æ¨å¯¼
- ç½‘ç»œæ¶æ„ä¸è¶…å‚æ•°
- è®­ç»ƒ/æ¨ç†ç®—æ³•ä¼ªä»£ç 
- ä¼˜åŠ£åŠ¿å¯¹æ¯”ä¸é€‰å‹å»ºè®®

---

# æ–¹æ¡ˆå¯¹æ¯”æ€»è§ˆ

| ç»´åº¦ | æ–¹æ¡ˆ1ï¼šå¤šé˜¶æ®µæ³¨æ„åŠ›GAT + ç¡¬çº¦æŸ | æ–¹æ¡ˆ2ï¼šè®°å¿†å¢å¼ºå¯¹æ¯”å­¦ä¹  + è½¯è§„åˆ™ | æ–¹æ¡ˆ3ï¼šå› æœå›¾ç½‘ç»œ + åäº‹å®æ¨ç† |
|------|------|------|------|
| **æ ¸å¿ƒæ€æƒ³** | æ˜¾å¼è§„åˆ™çº¦æŸ + å¤šå°ºåº¦æ³¨æ„åŠ› | æ­£å¸¸æ¨¡å¼è®°å¿†åº“ + å¯¹æ¯”åº¦é‡ | å› æœæ¨ç† + åäº‹å®è§£é‡Š |
| **ç›‘ç£éœ€æ±‚** | æ— æ ‡ç­¾ï¼ˆè§„åˆ™ä»£æ›¿ï¼‰ | æ— æ ‡ç­¾ï¼ˆè‡ªç›‘ç£ï¼‰ | æ— æ ‡ç­¾ï¼ˆå› æœå…ˆéªŒï¼‰ |
| **å¯è§£é‡Šæ€§** | â˜…â˜…â˜…â˜†â˜† æ³¨æ„åŠ›æƒé‡ | â˜…â˜…â˜…â˜…â˜† è®°å¿†æ£€ç´¢è·¯å¾„ | â˜…â˜…â˜…â˜…â˜… å› æœé“¾æ¨ç† |
| **å·¥ç¨‹å¤æ‚åº¦** | â˜…â˜…â˜†â˜†â˜† ä¸­ç­‰ | â˜…â˜…â˜…â˜†â˜† è¾ƒé«˜ | â˜…â˜…â˜…â˜…â˜† é«˜ |
| **è®­ç»ƒç¨³å®šæ€§** | â˜…â˜…â˜…â˜…â˜† è§„åˆ™æä¾›å¼ºç›‘ç£ | â˜…â˜…â˜…â˜†â˜† å¯¹æ¯”å­¦ä¹ éœ€è°ƒå‚ | â˜…â˜…â˜†â˜†â˜† å› æœå‘ç°æ˜“è¿‡æ‹Ÿåˆ |
| **æ‰©å±•æ€§** | â˜…â˜…â˜…â˜†â˜† æ–°è§„åˆ™éœ€æ‰‹å·¥ç¼–å†™ | â˜…â˜…â˜…â˜…â˜† è®°å¿†åº“è‡ªé€‚åº” | â˜…â˜…â˜…â˜…â˜… å› æœå›¾å¯è¿ç§» |
| **è®¡ç®—æˆæœ¬** | â˜…â˜…â˜…â˜†â˜† ä¸­ç­‰ï¼ˆå¤šå¤´æ³¨æ„åŠ›ï¼‰ | â˜…â˜…â˜…â˜…â˜† é«˜ï¼ˆæ£€ç´¢+å¯¹æ¯”ï¼‰ | â˜…â˜…â˜…â˜…â˜… å¾ˆé«˜ï¼ˆå› æœæ¨ç†ï¼‰ |
| **MVP é€‚é…åº¦** | â˜…â˜…â˜…â˜…â˜… æœ€é€‚åˆå¿«é€Ÿäº¤ä»˜ | â˜…â˜…â˜…â˜†â˜† éœ€æ›´å¤šæ•°æ® | â˜…â˜…â˜†â˜†â˜† ç ”ç©¶æ€§å¼º |

**æ¨è**: 
- **MVP é¦–é€‰ï¼šæ–¹æ¡ˆ1**ï¼ˆå·¥ç¨‹é£é™©ä½ï¼Œå¯è§£é‡Šæ€§è¾¾æ ‡ï¼‰
- **ITER-02 æ¼”è¿›ï¼šæ–¹æ¡ˆ2**ï¼ˆæ•°æ®é‡å¢åŠ åæ€§èƒ½æ›´ä¼˜ï¼‰
- **è®ºæ–‡åˆ›æ–°ï¼šæ–¹æ¡ˆ3**ï¼ˆå­¦æœ¯ä»·å€¼é«˜ï¼Œå¯ä½œä¸ºé•¿æœŸæ–¹å‘ï¼‰

---

# æ–¹æ¡ˆ1ï¼šå¤šé˜¶æ®µæ³¨æ„åŠ›å¢å¼º GAT + ç¡¬çº¦æŸè§„åˆ™èåˆ

## 1.1 æ ¸å¿ƒæ€æƒ³
å°†äº¤é€šåœºæ™¯å»ºæ¨¡ä¸º**å¼‚æ„æ—¶ç©ºå›¾**ï¼Œé€šè¿‡å¤šå¤´å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰å­¦ä¹ å®ä½“é—´å…³ç³»ï¼ŒåŒæ—¶å¼•å…¥**æ˜¾å¼è§„åˆ™çº¦æŸæŸå¤±**å¼ºåˆ¶æ¨¡å‹ç¬¦åˆäº¤é€šæ³•è§„ã€‚é‡‡ç”¨**ä¸‰é˜¶æ®µæ³¨æ„åŠ›æœºåˆ¶**ï¼ˆå±€éƒ¨â†’å…¨å±€â†’è§„åˆ™èšç„¦ï¼‰æå‡è¿è§„å®ä½“çš„è¯†åˆ«å‡†ç¡®æ€§ã€‚

## 1.2 æ•°å­¦æ¨¡å‹

### 1.2.1 åœºæ™¯å›¾å®šä¹‰
ç»™å®šæ—¶åˆ» $t$ çš„äº¤é€šåœºæ™¯ï¼Œæ„é€ æœ‰å‘å›¾ $\mathcal{G}_t = (\mathcal{V}_t, \mathcal{E}_t, \mathbf{X}_t, \mathbf{A}_t)$ï¼š

$$
\begin{aligned}
\mathcal{V}_t &= \{v_1, \dots, v_{N_{\text{car}}}, v_{N_{\text{car}}+1}, \dots, v_{N_{\text{car}}+N_{\text{light}}}, v_{\text{stop}}\} \\
\mathbf{X}_t &\in \mathbb{R}^{|\mathcal{V}_t| \times d_{\text{feat}}} \quad \text{(èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ)} \\
\mathbf{A}_t &\in \{0,1\}^{|\mathcal{V}_t| \times |\mathcal{V}_t|} \quad \text{(é‚»æ¥çŸ©é˜µ)}
\end{aligned}
$$

**èŠ‚ç‚¹ç‰¹å¾** $\mathbf{x}_i$ åŒ…å«ï¼š
- è½¦è¾†èŠ‚ç‚¹ï¼šä½ç½® $(x, y)$ã€é€Ÿåº¦ $(v_x, v_y)$ã€æœå‘ $\theta$ã€bounding box $(w, h)$ã€åœæ­¢çº¿è·ç¦» $d_{\text{stop}}$
- äº¤é€šç¯èŠ‚ç‚¹ï¼šä½ç½®ã€çŠ¶æ€ one-hot `[red, yellow, green]`ã€ç½®ä¿¡åº¦
- åœæ­¢çº¿èŠ‚ç‚¹ï¼šçº¿æ®µç«¯ç‚¹ $(x_1, y_1, x_2, y_2)$

**è¾¹æ„å»ºç­–ç•¥**ï¼š
$$
\mathbf{A}_{ij} = \begin{cases}
1, & \text{if } \|\mathbf{p}_i - \mathbf{p}_j\|_2 < r_{\text{spatial}} \text{ and } \text{type}(v_i) \neq \text{type}(v_j) \\
1, & \text{if } v_i \text{ is car and } v_j \text{ is nearest traffic light} \\
0, & \text{otherwise}
\end{cases}
$$
å…¶ä¸­ $r_{\text{spatial}} = 50m$ï¼ˆå¯é…ç½®ï¼‰ã€‚

### 1.2.2 å¤šé˜¶æ®µæ³¨æ„åŠ›æ¶æ„

> **æŠ€æœ¯å‹˜è¯¯ä¿®æ­£ï¼ˆ2025-12-03ï¼‰**ï¼šè¡¥å……ä¸‰é˜¶æ®µæ³¨æ„åŠ›çš„è¯¦ç»†å®ç°ç»†èŠ‚ï¼Œæ˜ç¡®å±€éƒ¨â†’å…¨å±€â†’è§„åˆ™èšç„¦çš„å…·ä½“æœºåˆ¶ã€‚  
> è¯¦è§ï¼š`docs/design/TECHNICAL_CORRECTIONS.md` é—®é¢˜5

#### é˜¶æ®µ1ï¼šå±€éƒ¨å…³ç³»ç¼–ç ï¼ˆLocal GATï¼‰

**å®šä¹‰**ï¼šåŸºäºç©ºé—´é‚»è¿‘æ€§å’Œå®ä½“ç±»å‹çš„**ç¨€ç–å›¾æ³¨æ„åŠ›**ã€‚

**é‚»æ¥çŸ©é˜µæ„å»ºç­–ç•¥**ï¼š
```python
def build_local_adjacency(entities, r_spatial=50.0):
    """
    å±€éƒ¨é‚»æ¥ï¼šä»…è¿æ¥ç©ºé—´é‚»è¿‘ä¸”å¼‚æ„çš„å®ä½“
    
    è¾¹ç±»å‹ï¼š
    1. è½¦è¾†-è½¦è¾†ï¼ˆè·ç¦»<30mï¼‰
    2. è½¦è¾†-äº¤é€šç¯ï¼ˆè·ç¦»<50mï¼‰
    3. è½¦è¾†-åœæ­¢çº¿ï¼ˆè·ç¦»<100mï¼‰
    """
    edges = []
    for i, e_i in enumerate(entities):
        for j, e_j in enumerate(entities):
            if i >= j:
                continue
            
            dist = np.linalg.norm(e_i.pos - e_j.pos)
            
            # å¼‚æ„è¿æ¥
            if e_i.type != e_j.type:
                if e_i.type == 'car' and e_j.type == 'light' and dist < 50:
                    edges.append((i, j))
                elif e_i.type == 'car' and e_j.type == 'stop' and dist < 100:
                    edges.append((i, j))
            # åŒæ„è¿æ¥ï¼ˆä»…è½¦è¾†ï¼‰
            elif e_i.type == 'car' and e_j.type == 'car' and dist < 30:
                edges.append((i, j))
    
    return torch.tensor(edges).T  # [2, E]
```

å¯¹æ¯ä¸ªè½¦è¾†èŠ‚ç‚¹ï¼Œå­¦ä¹ å…¶ä¸é‚»è¿‘å®ä½“çš„å…³ç³»ï¼š

$$
\begin{aligned}
\mathbf{h}_i^{(0)} &= \text{LayerNorm}(\mathbf{W}_0 \mathbf{x}_i + \mathbf{b}_0) \\
\alpha_{ij}^{(l,k)} &= \frac{\exp\left(\text{LeakyReLU}\left(\mathbf{a}_k^\top [\mathbf{W}_k^{(l)} \mathbf{h}_i^{(l-1)} \| \mathbf{W}_k^{(l)} \mathbf{h}_j^{(l-1)}]\right)\right)}{\sum_{j' \in \mathcal{N}(i)} \exp\left(\text{LeakyReLU}\left(\mathbf{a}_k^\top [\mathbf{W}_k^{(l)} \mathbf{h}_i^{(l-1)} \| \mathbf{W}_k^{(l)} \mathbf{h}_{j'}^{(l-1)}]\right)\right)} \\
\mathbf{h}_i^{(l,k)} &= \sum_{j \in \mathcal{N}(i)} \alpha_{ij}^{(l,k)} \mathbf{W}_k^{(l)} \mathbf{h}_j^{(l-1)} \\
\mathbf{h}_i^{(l)} &= \text{GELU}\left(\frac{1}{K} \sum_{k=1}^K \mathbf{h}_i^{(l,k)}\right) + \mathbf{h}_i^{(l-1)} \quad \text{(å¤šå¤´å¹³å‡ + æ®‹å·®)}
\end{aligned}
$$

**ç‰¹ç‚¹**ï¼š
- âœ… ç¨€ç–è¿æ¥ï¼ˆè¾¹æ•° $E \ll N^2$ï¼‰
- âœ… ç©ºé—´å±€éƒ¨æ€§ï¼ˆä¸åŒç±»å‹å®ä½“æœ‰ä¸åŒè¿æ¥åŠå¾„ï¼‰
- âœ… å¤šè·³ä¼ æ’­ï¼ˆ3å±‚GAT â†’ 3è·³æ„Ÿå—é‡ï¼‰

è¶…å‚æ•°ï¼š$L=3$ å±‚ï¼Œ$K=8$ å¤´ï¼Œ$d_h = 128$ éšè—ç»´åº¦ã€‚

#### é˜¶æ®µ2ï¼šå…¨å±€ä¸Šä¸‹æ–‡èåˆï¼ˆGlobal Attentionï¼‰

**å®šä¹‰**ï¼šé€šè¿‡**è™šæ‹Ÿå…¨å±€èŠ‚ç‚¹**èšåˆåœºæ™¯çº§ä¸Šä¸‹æ–‡ï¼ˆç±»ä¼¼Transformerçš„[CLS] tokenï¼‰ã€‚

**å®ç°ä»£ç **ï¼š
```python
class GlobalSceneAttention(nn.Module):
    def __init__(self, hidden_dim=128):
        super().__init__()
        # å…¨å±€èŠ‚ç‚¹åˆå§‹åŒ–ï¼ˆå¯å­¦ä¹ ï¼‰
        self.global_query = nn.Parameter(torch.randn(1, hidden_dim))
        
        # Transformerå¼å¤šå¤´è‡ªæ³¨æ„åŠ›
        self.multihead_attn = nn.MultiheadAttention(
            embed_dim=hidden_dim, num_heads=4, dropout=0.1
        )
        
        # èåˆMLP
        self.fusion = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.GELU(),
            nn.LayerNorm(hidden_dim)
        )
    
    def forward(self, h_local):
        # Step 1: å…¨å±€èŠ‚ç‚¹èšåˆæ‰€æœ‰å±€éƒ¨èŠ‚ç‚¹ä¿¡æ¯
        global_context, attn_weights = self.multihead_attn(
            query=self.global_query.unsqueeze(0),
            key=h_local.unsqueeze(0),
            value=h_local.unsqueeze(0)
        )
        
        # Step 2: å¹¿æ’­å…¨å±€ä¿¡æ¯åˆ°æ¯ä¸ªå±€éƒ¨èŠ‚ç‚¹
        global_context = global_context.squeeze(0).expand(N, -1)
        
        # Step 3: èåˆå±€éƒ¨+å…¨å±€ï¼ˆæ®‹å·®è¿æ¥ï¼‰
        h_fused = torch.cat([h_local, global_context], dim=-1)
        h_global = self.fusion(h_fused) + h_local
        
        return h_global, attn_weights
```

**æ•°å­¦å½¢å¼**ï¼š
$$
\begin{aligned}
\mathbf{g} &= \text{softmax}\left(\frac{\mathbf{Q}_g \mathbf{K}_h^\top}{\sqrt{d_h}}\right) \mathbf{V}_h \quad \text{where } \mathbf{K}_h = [\mathbf{h}_1^{(L)}, \dots, \mathbf{h}_N^{(L)}] \\
\tilde{\mathbf{h}}_i &= \mathbf{h}_i^{(L)} + \text{MLP}_{\text{fuse}}([\mathbf{h}_i^{(L)} \| \mathbf{g}])
\end{aligned}
$$

**ç‰¹ç‚¹**ï¼š
- âœ… å…¨è¿æ¥ï¼ˆå…¨å±€èŠ‚ç‚¹ä¸æ‰€æœ‰å±€éƒ¨èŠ‚ç‚¹äº¤äº’ï¼‰
- âœ… åœºæ™¯çº§ä¿¡æ¯ï¼ˆäº¤é€šå¯†åº¦ã€æ•´ä½“æµåŠ¨æ€§ç­‰ï¼‰
- âœ… è®¡ç®—é«˜æ•ˆï¼ˆO(N) vs Transformerçš„O(NÂ²)ï¼‰

#### é˜¶æ®µ3ï¼šè§„åˆ™èšç„¦æ³¨æ„åŠ›ï¼ˆRule-Focused Attentionï¼‰

**å®šä¹‰**ï¼šåŸºäº**è§„åˆ™è¯­ä¹‰**çš„åŠ æƒæ³¨æ„åŠ›é‡åˆ†é…ã€‚

**å®ç°ä»£ç **ï¼š
```python
class RuleFocusedAttention(nn.Module):
    def __init__(self, hidden_dim=128):
        super().__init__()
        # è§„åˆ™ç›¸å…³æ€§è¯„åˆ†ç½‘ç»œ
        self.rule_scorer = nn.Sequential(
            nn.Linear(hidden_dim * 3, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1),
            nn.Sigmoid()
        )
        
        # è§„åˆ™åµŒå…¥ï¼ˆå¯å­¦ä¹ ï¼‰
        self.rule_embeddings = nn.Embedding(5, hidden_dim)
    
    def forward(self, h_fused, entity_types, rule_id=0):
        # æå–è§„åˆ™ç›¸å…³å®ä½“
        car_mask = (entity_types == 0)
        h_cars = h_fused[car_mask]
        
        # è®¡ç®—æ¯ä¸ªè½¦è¾†ä¸è§„åˆ™ç›¸å…³å®ä½“çš„æ³¨æ„åŠ›
        rule_emb = self.rule_embeddings(torch.tensor([rule_id]))
        
        for h_car in h_cars:
            concat_feat = torch.cat([h_car, h_light, h_stop], dim=0)
            rule_score = self.rule_scorer(concat_feat)
            h_weighted = h_car * rule_score + rule_emb * (1 - rule_score)
        
        return h_rule_focused, rule_attention
```

**æ•°å­¦å½¢å¼**ï¼š
$$
\begin{aligned}
\beta_{i,\text{light}} &= \text{sigmoid}\left(\mathbf{w}_{\text{rule}}^\top [\tilde{\mathbf{h}}_i \| \mathbf{h}_{\text{light}} \| \mathbf{h}_{\text{stop}}]\right) \\
\mathbf{h}_i^{\text{rule}} &= \beta_{i,\text{light}} \odot \tilde{\mathbf{h}}_i + (1-\beta_{i,\text{light}}) \odot \mathbf{e}_{\text{rule}}
\end{aligned}
$$

**ç‰¹ç‚¹**ï¼š
- âœ… è§„åˆ™è¯­ä¹‰æ³¨å…¥ï¼ˆå¯å­¦ä¹ çš„rule embeddingï¼‰
- âœ… åŠ¨æ€èšç„¦ï¼ˆä¸åŒè½¦è¾†è·å¾—ä¸åŒæƒé‡ï¼‰
- âœ… å¯æ‰©å±•ï¼ˆæ”¯æŒå¤šç§è§„åˆ™ï¼‰

æœ€ç»ˆå¼‚å¸¸åˆ†æ•°ï¼š
$$
s_i^{\text{model}} = \sigma\left(\text{MLP}_{\text{score}}(\mathbf{h}_i^{\text{rule}})\right) \in [0,1]
$$

### 1.2.3 è§„åˆ™çº¦æŸæŸå¤±

> **é‡å¤§ä¿®æ­£ï¼ˆ2025-12-03ï¼‰**ï¼šåŸå…¬å¼å­˜åœ¨è·ç¦»é¡¹é€»è¾‘é”™è¯¯å’Œé€Ÿåº¦é¡¹è¾¹ç•Œæ¡ä»¶é”™è¯¯ã€‚ç°é‡æ–°è®¾è®¡ç‰©ç†æ­£ç¡®çš„è§„åˆ™åˆ†æ•°å…¬å¼ï¼ŒåŒºåˆ†"æ¥è¿‘åœæ­¢çº¿"å’Œ"é—¯è¿‡åœæ­¢çº¿"ä¸¤ç§æƒ…å†µã€‚  
> è¯¦è§ï¼š`docs/design/TECHNICAL_CORRECTIONS.md` é—®é¢˜1 + ç³»ç»Ÿæ€§é‡æ„

#### çº¢ç¯åœè§„åˆ™å½¢å¼åŒ–

**ç‰©ç†æ¨¡å‹è¯´æ˜**ï¼š
- **è§„åˆ™åˆ†æ•°è¯­ä¹‰**ï¼šè¿è§„ç¨‹åº¦ï¼ˆ0=æ— è¿è§„ï¼Œ1=ä¸¥é‡è¿è§„ï¼‰
- **è·ç¦»çº¦å®š**ï¼š$d > 0$è¡¨ç¤ºè½¦è¾†åœ¨åœæ­¢çº¿å‰ï¼Œ$d < 0$è¡¨ç¤ºè½¦è¾†å·²è¿‡åœæ­¢çº¿
- **é€Ÿåº¦çº¦å®š**ï¼š$v = 0$è¡¨ç¤ºå®Œå…¨åœæ­¢ï¼ˆæ— è¿è§„ï¼‰ï¼Œ$v > 0$è¡¨ç¤ºç§»åŠ¨ä¸­

**ç¡¬é˜ˆå€¼ç‰ˆï¼ˆç”¨äºéªŒæ”¶æµ‹è¯•ï¼‰**ï¼š
$$
\text{violation}(i) = \begin{cases}
1, & \text{if } \text{light}_{\text{state}} = \text{red} \land \left(d_{\text{stop}}(i) < 0 \lor (0 \le d_{\text{stop}}(i) < \tau_d \land v(i) > \tau_v)\right) \\
0, & \text{otherwise}
\end{cases}
$$
å…¶ä¸­ $\tau_d = 5m$ï¼Œ$\tau_v = 0.5 m/s$ã€‚

**è§„åˆ™åˆ†æ•°ï¼ˆè½¯åŒ–ç‰ˆï¼Œå®Œå…¨å¯å¾®åˆ†ï¼‰**ï¼š

ä½¿ç”¨Gumbel-Softmaxè½¯åŒ–äº¤é€šç¯çŠ¶æ€ï¼š
$$
w_{\text{light}} = \text{GumbelSoftmax}([p_{\text{red}}, p_{\text{yellow}}, p_{\text{green}}], \tau_{\text{temp}}=0.5)[0]
$$

**åˆ†æ®µè·ç¦»-é€Ÿåº¦è¯„åˆ†å‡½æ•°**ï¼š
$$
f_{\text{dv}}(d, v) = \begin{cases}
\sigma\left(\alpha_{\text{cross}} \cdot (-d)\right) \cdot \sigma\left(\alpha_v \cdot v\right), & \text{if } d < 0 \quad \text{(å·²è¿‡çº¿)} \\
\sigma\left(\alpha_d \cdot (\tau_d - d)\right) \cdot \sigma\left(\alpha_v \cdot (v - \tau_v)\right), & \text{if } 0 \le d < \tau_d \quad \text{(æ¥è¿‘åœæ­¢çº¿)} \\
0, & \text{if } d \ge \tau_d \quad \text{(è¿œç¦»åœæ­¢çº¿)}
\end{cases}
$$

**æœ€ç»ˆè§„åˆ™åˆ†æ•°**ï¼š
$$
s_i^{\text{rule}} = w_{\text{light}} \cdot f_{\text{dv}}(d_{\text{stop}}(i), v(i))
$$

**å‚æ•°è¯´æ˜**ï¼š
- $\alpha_{\text{cross}} = 3.0$ï¼šè¿‡çº¿è¿è§„æ•æ„Ÿåº¦
- $\alpha_d = 2.0$ï¼šæ¥è¿‘åœæ­¢çº¿æ•æ„Ÿåº¦
- $\alpha_v = 5.0$ï¼šé€Ÿåº¦æ•æ„Ÿåº¦
- $\tau_d = 5.0m$ï¼Œ$\tau_v = 0.5 m/s$ï¼šé˜ˆå€¼

**ç‰©ç†æ„ä¹‰éªŒè¯**ï¼š
- å®Œå…¨åœæ­¢ï¼ˆ$v=0$ï¼Œ$d=10m>\tau_d$ï¼‰ï¼š$s^{\text{rule}} = 0$ âœ…
- é—¯è¿‡åœæ­¢çº¿ï¼ˆ$d=-2m$ï¼Œ$v=2m/s$ï¼‰ï¼š$s^{\text{rule}} \approx 0.998$ âœ…
- è¿œç¦»åœæ­¢çº¿ï¼ˆ$d=10m$ï¼‰ï¼š$s^{\text{rule}} = 0$ âœ…

**å®ç°ä»£ç **ï¼š
```python
import torch
import torch.nn.functional as F

def compute_rule_score_differentiable(
    light_probs: torch.Tensor,  # [B, 3] - [red, yellow, green]
    distances: torch.Tensor,    # [B] - distance (æ­£=æœªè¿‡çº¿ï¼Œè´Ÿ=å·²è¿‡çº¿)
    velocities: torch.Tensor,   # [B] - vehicle velocity
    tau_d: float = 5.0,
    tau_v: float = 0.5,
    alpha_d: float = 2.0,
    alpha_v: float = 5.0,
    alpha_cross: float = 3.0,
    temperature: float = 0.5,
    training: bool = True,
):
    """ç‰©ç†æ­£ç¡®çš„å®Œå…¨å¯å¯¼è§„åˆ™è¯„åˆ†å‡½æ•°"""
    # Gumbel-Softmaxè½¯åŒ–
    if training:
        light_weights = F.gumbel_softmax(
            torch.log(light_probs + 1e-10), 
            tau=temperature, 
            hard=False
        )[:, 0]
    else:
        light_weights = light_probs[:, 0]
    
    # åˆ†æ®µè·ç¦»-é€Ÿåº¦è¯„åˆ†
    B = distances.size(0)
    f_dv = torch.zeros(B, device=distances.device)
    
    # æƒ…å†µ1ï¼šå·²è¿‡çº¿ï¼ˆd < 0ï¼‰
    crossed_mask = (distances < 0)
    if crossed_mask.any():
        f_dv[crossed_mask] = (
            torch.sigmoid(alpha_cross * (-distances[crossed_mask])) *
            torch.sigmoid(alpha_v * velocities[crossed_mask])
        )
    
    # æƒ…å†µ2ï¼šæ¥è¿‘åœæ­¢çº¿ï¼ˆ0 <= d < tau_dï¼‰
    approaching_mask = (distances >= 0) & (distances < tau_d)
    if approaching_mask.any():
        f_dv[approaching_mask] = (
            torch.sigmoid(alpha_d * (tau_d - distances[approaching_mask])) *
            torch.sigmoid(alpha_v * (velocities[approaching_mask] - tau_v))
        )
    
    # æƒ…å†µ3ï¼šè¿œç¦»åœæ­¢çº¿ï¼ˆd >= tau_dï¼‰ï¼šf_dvä¿æŒä¸º0
    
    # ç»„åˆ
    rule_scores = light_weights * f_dv
    
    return rule_scores
```

#### æ€»æŸå¤±å‡½æ•°

> **é‡å¤§ä¿®æ­£ï¼ˆ2025-12-03ï¼‰**ï¼šç»Ÿä¸€æ³¨æ„åŠ›ä¸€è‡´æ€§æŸå¤±å®šä¹‰ï¼Œæ˜ç¡®GATæ³¨æ„åŠ›ä¸è§„åˆ™èšç„¦æ³¨æ„åŠ›çš„å…³ç³»ã€‚

$$
\begin{aligned}
\mathcal{L}_{\text{total}} &= \mathcal{L}_{\text{recon}} + \lambda_1 \mathcal{L}_{\text{rule}} + \lambda_2 \mathcal{L}_{\text{attn}} + \lambda_3 \mathcal{L}_{\text{reg}} \\
\\
\mathcal{L}_{\text{recon}} &= -\frac{1}{N_{\text{car}}} \sum_{i=1}^{N_{\text{car}}} \left[s_i^{\text{rule}} \log s_i^{\text{model}} + (1-s_i^{\text{rule}}) \log(1-s_i^{\text{model}})\right] \quad \text{(BCE)} \\
\\
\mathcal{L}_{\text{rule}} &= \frac{1}{N_{\text{car}}} \sum_{i=1}^{N_{\text{car}}} \left|s_i^{\text{model}} - s_i^{\text{rule}}\right|^2 \quad \text{(MSE)} \\
\\
\mathcal{L}_{\text{attn}} &= \mathcal{L}_{\text{attn}}^{\text{GAT}} + \mathcal{L}_{\text{attn}}^{\text{rule}} \quad \text{(åŒå±‚ç›‘ç£)} \\
\\
\mathcal{L}_{\text{attn}}^{\text{GAT}} &= \frac{1}{|\mathcal{I}_{\text{viol}}|} \sum_{i \in \mathcal{I}_{\text{viol}}} \left(1 - \max_{j \in \mathcal{N}_{\text{rule}}(i)} \alpha_{ij}^{(L)}\right)^2 \quad \text{(å±€éƒ¨æ³¨æ„åŠ›)} \\
\\
\mathcal{L}_{\text{attn}}^{\text{rule}} &= \frac{1}{|\mathcal{I}_{\text{viol}}|} \sum_{i \in \mathcal{I}_{\text{viol}}} \left(1 - \beta_i\right)^2 \quad \text{(è§„åˆ™èšç„¦)} \\
\\
\mathcal{L}_{\text{reg}} &= \sum_{l=1}^L \|\mathbf{W}^{(l)}\|_F^2
\end{aligned}
$$

å…¶ä¸­ï¼š
- $\mathcal{I}_{\text{viol}} = \{i : s_i^{\text{rule}} > 0.5\}$ï¼šè¿è§„è½¦è¾†é›†åˆ
- $\mathcal{N}_{\text{rule}}(i) = \{j : j \in \mathcal{N}(i) \land \text{type}(j) \in \{\text{light, stop}\}\}$ï¼šè½¦è¾†$i$çš„è§„åˆ™ç›¸å…³é‚»å±…
- $\alpha_{ij}^{(L)}$ï¼šGATç¬¬$L$å±‚çš„è¾¹æ³¨æ„åŠ›æƒé‡
- $\beta_i$ï¼šè§„åˆ™èšç„¦æ³¨æ„åŠ›åˆ†æ•°

è¶…å‚æ•°ï¼š$\lambda_1 = 0.5$ï¼Œ$\lambda_2 = 0.3$ï¼ˆå…¶ä¸­GATå’Œè§„åˆ™å„å ä¸€åŠï¼‰ï¼Œ$\lambda_3 = 1e-4$ã€‚

## 1.3 è®­ç»ƒç®—æ³•

```python
Algorithm: Multi-Stage Attention GAT Training

Input: 
  - Dataset D = {G_1, ..., G_M} (scene graphs)
  - Rule thresholds Ï„_d, Ï„_v
  - Hyperparameters: epochs E, batch_size B, lr Î·
  
Output: 
  - Trained model Î¸*
  
1: Initialize model parameters Î¸ ~ N(0, 0.02)
2: optimizer â† AdamW(Î¸, lr=Î·, weight_decay=1e-4)
3: scheduler â† CosineAnnealingLR(optimizer, T_max=E)
4: 
5: for epoch = 1 to E do
6:     for batch G_b in DataLoader(D, batch_size=B, shuffle=True) do
7:         # Forward pass
8:         X, A, entities â† G_b.unpack()
9:         
10:        # Stage 1: Local GAT
11:        H^(0) â† LayerNorm(W_0 X + b_0)
12:        for layer l = 1 to L do
13:            for head k = 1 to K do
14:                Î±^(l,k) â† MultiHeadAttention(H^(l-1), A)
15:                H^(l,k) â† MessagePassing(H^(l-1), Î±^(l,k))
16:            H^(l) â† GELU(Mean(H^(l,1:K))) + H^(l-1)
17:        
18:        # Stage 2: Global context
19:        g â† GlobalAttentionPooling(H^(L))
20:        H_tilde â† H^(L) + MLP_fuse([H^(L) || g])
21:        
22:        # Stage 3: Rule-focused attention
23:        Î² â† RuleFocusedAttention(H_tilde, entities)
24:        H_rule â† Î² âŠ™ H_tilde
25:        s_model â† Sigmoid(MLP_score(H_rule))
26:        
27:        # Compute rule scores
28:        s_rule â† ComputeRuleScores(entities, Ï„_d, Ï„_v)
29:        
30:        # Loss computation
31:        L_recon â† BinaryCrossEntropy(s_model, s_rule)
32:        L_rule â† MSE(s_model, s_rule)
33:        L_attn â† AttentionConsistencyLoss(Î±, Î², s_rule)
34:        L_reg â† sum(W^2 for W in Î¸)
35:        
36:        L_total â† L_recon + Î»_1*L_rule + Î»_2*L_attn + Î»_3*L_reg
37:        
38:        # Backward pass
39:        optimizer.zero_grad()
40:        L_total.backward()
41:        clip_grad_norm_(Î¸, max_norm=1.0)
42:        optimizer.step()
43:        
44:        # Logging
45:        if step % 50 == 0:
46:            log_metrics(L_total, L_recon, L_rule, L_attn)
47:            visualize_attention(Î±, Î², entities)
48:    
49:    scheduler.step()
50:    
51:    # Validation
52:    if epoch % 5 == 0:
53:        val_metrics â† evaluate(model, D_val)
54:        save_checkpoint(Î¸, epoch, val_metrics)
55:
56: return Î¸
```

## 1.4 æ¨ç†ç®—æ³•

```python
Algorithm: Violation Detection & Explanation

Input:
  - Scene graph G_t
  - Trained model Î¸*
  - Rule thresholds Ï„_d, Ï„_v
  
Output:
  - Violation report {entity_id, score, explanation, attention_map}

1: # Load model and preprocess
2: model â† load_checkpoint(Î¸*)
3: X, A, entities â† preprocess(G_t)
4:
5: # Forward inference
6: with torch.no_grad():
7:     H, Î±, Î² â† model.forward(X, A, return_attention=True)
8:     s_model â† model.score_head(H)
9:     s_rule â† compute_rule_scores(entities, Ï„_d, Ï„_v)
10:
11: # Aggregate scores
12: s_final â† 0.6 * s_model + 0.4 * s_rule
13:
14: # Generate explanations
15: violations â† []
16: for i in range(len(entities)):
17:     if s_final[i] > threshold_violation (e.g., 0.7):
18:         explanation â† {
19:             'entity_id': entities[i].id,
20:             'type': entities[i].type,
21:             'model_score': s_model[i],
22:             'rule_score': s_rule[i],
23:             'distance_to_stopline': entities[i].d_stop,
24:             'velocity': entities[i].velocity,
25:             'traffic_light_state': get_nearest_light(entities[i]).state,
26:             'attention_to_light': Î±[i, light_idx],
27:             'attention_to_stopline': Î±[i, stop_idx],
28:             'rule_focus': Î²[i]
29:         }
30:         
31:         # Generate attention heatmap
32:         attention_map â† visualize_attention(
33:             image=G_t.image,
34:             entities=entities,
35:             attention_weights=Î±[i],
36:             focal_entity=i
37:         )
38:         explanation['attention_map_path'] â† save(attention_map)
39:         
40:         violations.append(explanation)
41:
42: # Generate report
43: report â† format_report(violations, timestamp=G_t.timestamp)
44: return report
```

## 1.5 ç½‘ç»œæ¶æ„ç»†èŠ‚

```python
class MultiStageAttentionGAT(nn.Module):
    def __init__(
        self,
        input_dim: int = 10,          # å®ä½“ç‰¹å¾ç»´åº¦
        hidden_dim: int = 128,        # GATéšè—å±‚ç»´åº¦
        num_gat_layers: int = 3,      # GATå±‚æ•°
        num_heads: int = 8,           # å¤šå¤´æ³¨æ„åŠ›å¤´æ•°
        dropout: float = 0.1,         # Dropoutæ¦‚ç‡
        alpha: float = 0.2,           # LeakyReLUè´Ÿæ–œç‡
    ):
        super().__init__()
        
        # Stage 1: Local GAT layers
        self.input_proj = nn.Linear(input_dim, hidden_dim)
        self.layer_norm = nn.LayerNorm(hidden_dim)
        
        self.gat_layers = nn.ModuleList([
            GATConv(
                in_channels=hidden_dim,
                out_channels=hidden_dim // num_heads,
                heads=num_heads,
                dropout=dropout,
                negative_slope=alpha,
                add_self_loops=True,
                concat=True
            )
            for _ in range(num_gat_layers)
        ])
        
        # Stage 2: Global attention
        self.global_attn = nn.MultiheadAttention(
            embed_dim=hidden_dim,
            num_heads=4,
            dropout=dropout,
            batch_first=True
        )
        self.fusion_mlp = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim)
        )
        
        # Stage 3: Rule-focused attention
        self.rule_query = nn.Parameter(torch.randn(1, hidden_dim))
        self.rule_attention = nn.Linear(hidden_dim * 3, 1)
        
        # Scoring head
        self.score_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
    
    def forward(
        self,
        x: Tensor,                    # [N, input_dim]
        edge_index: Tensor,           # [2, E]
        entity_types: Tensor,         # [N] (0=car, 1=light, 2=stop)
        return_attention: bool = False
    ):
        # Stage 1: Local GAT
        h = self.layer_norm(self.input_proj(x))
        attention_weights_local = []
        
        for gat_layer in self.gat_layers:
            h_new, attn = gat_layer(h, edge_index, return_attention_weights=True)
            h = F.gelu(h_new) + h  # Residual connection
            attention_weights_local.append(attn)
        
        # Stage 2: Global context
        h_global, attn_global = self.global_attn(
            query=h.unsqueeze(0),
            key=h.unsqueeze(0),
            value=h.unsqueeze(0)
        )
        h_global = h_global.squeeze(0)
        
        h_fused = h + self.fusion_mlp(torch.cat([h, h_global], dim=-1))
        
        # Stage 3: Rule-focused attention
        # Extract rule-relevant entities (traffic lights and stop lines)
        rule_mask = (entity_types == 1) | (entity_types == 2)
        h_rule_entities = h_fused[rule_mask]
        
        # Compute attention between cars and rule entities
        car_mask = (entity_types == 0)
        h_cars = h_fused[car_mask]
        
        # Broadcasting attention computation
        rule_focus = torch.zeros(h_cars.size(0), device=x.device)
        for i, h_car in enumerate(h_cars):
            attn_scores = []
            for h_rule in h_rule_entities:
                concat_feat = torch.cat([h_car, h_rule, h_car * h_rule], dim=-1)
                score = torch.sigmoid(self.rule_attention(concat_feat))
                attn_scores.append(score)
            if len(attn_scores) > 0:
                rule_focus[i] = torch.stack(attn_scores).max()
        
        h_cars_focused = h_cars * rule_focus.unsqueeze(-1)
        
        # Reconstruct full node embeddings
        h_final = torch.zeros_like(h_fused)
        h_final[car_mask] = h_cars_focused
        h_final[~car_mask] = h_fused[~car_mask]
        
        # Scoring
        scores = self.score_head(h_final[car_mask]).squeeze(-1)
        
        if return_attention:
            return scores, attention_weights_local, attn_global, rule_focus
        return scores
```

## 1.6 è‡ªè®­ç»ƒç­–ç•¥è¯¦ç»†

> **æŠ€æœ¯å‹˜è¯¯ä¿®æ­£ï¼ˆ2025-12-03ï¼‰**ï¼šè¡¥å……è‡ªè®­ç»ƒæœºåˆ¶çš„åŒè·¯å¾„ä¼ªæ ‡ç­¾ç­–ç•¥ï¼Œè§£å†³æ¨¡å‹ä¸è§„åˆ™å†²çªé—®é¢˜ã€‚  
> è¯¦è§ï¼š`docs/design/TECHNICAL_CORRECTIONS.md` é—®é¢˜4

### 1.6.1 é—®é¢˜åˆ†æï¼šæ¨¡å‹ä¸è§„åˆ™å†²çª

| åœºæ™¯ | è§„åˆ™åˆ¤å®š | æ¨¡å‹è¾“å‡º | å½“å‰å¤„ç† | é—®é¢˜ |
|------|---------|---------|---------|------|
| A | è¿è§„($s^{\text{rule}}=0.9$) | é«˜ç½®ä¿¡($s^{\text{model}}=0.85$) | âœ… ç”Ÿæˆä¼ªæ ‡ç­¾ | æ— å†²çª |
| B | è¿è§„($s^{\text{rule}}=0.9$) | ä½ç½®ä¿¡($s^{\text{model}}=0.3$) | â“ æœªå®šä¹‰ | **å†²çª** |
| C | æ­£å¸¸($s^{\text{rule}}=0.1$) | ä½ç½®ä¿¡($s^{\text{model}}=0.2$) | âœ… ç”Ÿæˆä¼ªæ ‡ç­¾ | æ— å†²çª |
| D | æ­£å¸¸($s^{\text{rule}}=0.1$) | é«˜ç½®ä¿¡($s^{\text{model}}=0.8$) | â“ æœªå®šä¹‰ | **å†²çª** |

### 1.6.2 ç­–ç•¥1ï¼šè§„åˆ™ä¼˜å…ˆï¼ˆä¿å®ˆç­–ç•¥ï¼Œæ¨èMVPï¼‰

```python
def generate_pseudo_labels_rule_priority(
    model_scores: torch.Tensor,
    rule_scores: torch.Tensor,
    attention_weights: torch.Tensor,
    threshold_conf: float = 0.85,
    threshold_consistency: float = 0.2,
):
    """
    è§„åˆ™ä¼˜å…ˆç­–ç•¥ï¼šä»…å½“æ¨¡å‹ä¸è§„åˆ™ä¸€è‡´æ—¶æ‰ç”Ÿæˆä¼ªæ ‡ç­¾
    
    é€‚ç”¨åœºæ™¯ï¼š
    - MVPé˜¶æ®µï¼ˆè§„åˆ™æ˜ç¡®ï¼Œæ¨¡å‹å°šæœªæ”¶æ•›ï¼‰
    - å†·å¯åŠ¨é˜¶æ®µï¼ˆå‰10-20 epochsï¼‰
    - å®‰å…¨å…³é”®åœºæ™¯ï¼ˆå®å¯æ¼æŠ¥ï¼Œä¸èƒ½è¯¯æŠ¥ï¼‰
    """
    pseudo_labels = []
    
    for i in range(len(model_scores)):
        # è®¡ç®—ç½®ä¿¡åº¦
        attention_focus = attention_weights[i].max().item()
        confidence = (
            torch.sigmoid(model_scores[i]).item() * 
            rule_scores[i].item() * 
            attention_focus
        )
        
        # ä¸€è‡´æ€§æ£€æŸ¥
        consistency = abs(model_scores[i].item() - rule_scores[i].item())
        
        # ç”Ÿæˆæ¡ä»¶ï¼ˆANDé€»è¾‘ï¼‰
        if (confidence > threshold_conf and 
            consistency < threshold_consistency and
            attention_focus > 0.3):
            
            # è§„åˆ™ä¼˜å…ˆï¼šä½¿ç”¨è§„åˆ™åˆ¤å®šä½œä¸ºä¼ªæ ‡ç­¾
            pseudo_labels.append({
                'label': 1 if rule_scores[i] > 0.5 else 0,
                'confidence': confidence,
                'source': 'rule_priority',
            })
        
        # å†²çªåœºæ™¯Bå¤„ç†ï¼šè§„åˆ™åˆ¤è¿è§„ï¼Œæ¨¡å‹ä½ç½®ä¿¡
        elif rule_scores[i] > 0.7 and model_scores[i] < 0.3:
            pseudo_labels.append({
                'label': 1,
                'confidence': 0.6,  # é™ä½æƒé‡
                'source': 'rule_override',
                'flag': 'model_disagree'
            })
    
    return pseudo_labels
```

### 1.6.3 ç­–ç•¥2ï¼šåŠ æƒèåˆï¼ˆå‡è¡¡ç­–ç•¥ï¼‰

```python
def generate_pseudo_labels_weighted(
    model_scores: torch.Tensor,
    rule_scores: torch.Tensor,
    attention_weights: torch.Tensor,
    weight_rule: float = 0.6,
    weight_model: float = 0.4,
    threshold_conf: float = 0.85,
):
    """
    åŠ æƒèåˆç­–ç•¥ï¼šç»¼åˆæ¨¡å‹ä¸è§„åˆ™
    
    é€‚ç”¨åœºæ™¯ï¼š
    - ä¸­æœŸè®­ç»ƒï¼ˆepoch 30-60ï¼‰
    - æ¨¡å‹é€æ¸å¯ä¿¡æ—¶
    """
    pseudo_labels = []
    
    for i in range(len(model_scores)):
        # åŠ æƒè¯„åˆ†
        fused_score = (
            weight_rule * rule_scores[i] + 
            weight_model * torch.sigmoid(model_scores[i])
        )
        
        # ç½®ä¿¡åº¦ï¼ˆè€ƒè™‘ä¸€è‡´æ€§å¥–åŠ±ï¼‰
        consistency_bonus = 1.0 - abs(model_scores[i] - rule_scores[i]) / 2.0
        confidence = fused_score * attention_weights[i].max() * consistency_bonus
        
        if confidence > threshold_conf:
            pseudo_labels.append({
                'label': 1 if fused_score > 0.5 else 0,
                'confidence': confidence.item(),
                'source': 'weighted_fusion',
            })
    
    return pseudo_labels
```

### 1.6.4 ç­–ç•¥3ï¼šåŠ¨æ€åˆ‡æ¢ï¼ˆè‡ªé€‚åº”ç­–ç•¥ï¼‰

```python
class AdaptivePseudoLabeler:
    def __init__(self):
        self.epoch = 0
        self.model_reliability = 0.0
    
    def select_strategy(self):
        """æ ¹æ®è®­ç»ƒé˜¶æ®µåŠ¨æ€é€‰æ‹©ç­–ç•¥"""
        if self.epoch < 20 or self.model_reliability < 0.7:
            return 'rule_priority'
        elif self.epoch < 60 or self.model_reliability < 0.85:
            return 'weighted_fusion'
        else:
            return 'model_priority'
    
    def update_reliability(self, val_auc, val_f1, rule_consistency):
        """è¯„ä¼°æ¨¡å‹å¯é åº¦"""
        self.model_reliability = (
            0.4 * val_auc + 
            0.3 * val_f1 + 
            0.3 * rule_consistency
        )
```

## 1.7 ä¼˜åŠ¿ä¸å±€é™ï¼ˆåŸºäºç³»ç»Ÿæ€§é‡æ„åï¼‰

> **æ›´æ–°ï¼ˆ2025-12-03ï¼‰**ï¼šåŸºäºç³»ç»Ÿæ€§é‡æ„åçš„æœ€æ–°è®¾è®¡

### ä¼˜åŠ¿
1. âœ… **ç‰©ç†æ­£ç¡®çš„è§„åˆ™å…¬å¼**ï¼šåˆ†æ®µå‡½æ•°è®¾è®¡ï¼ŒåŒºåˆ†"è¿‡çº¿"ã€"æ¥è¿‘"ã€"è¿œç¦»"ä¸‰ç§æƒ…å†µ
2. âœ… **å¤šå°ºåº¦æ³¨æ„åŠ›**ï¼šä»å±€éƒ¨â†’å…¨å±€â†’è§„åˆ™èšç„¦ï¼Œå±‚æ¬¡æ¸…æ™°
3. âœ… **æ¢¯åº¦æµç¨³å®š**ï¼šå¤šè·¯å¾„èåˆ+æ®‹å·®è¿æ¥+å‚æ•°å…±äº«ï¼Œç¡®ä¿å„é˜¶æ®µå‡è¢«è®­ç»ƒ
4. âœ… **å·¥ç¨‹å‹å¥½**ï¼šåŸºäºæˆç†Ÿçš„GATæ¶æ„ï¼ŒGPUæ˜¾å­˜éœ€æ±‚ä»…~520MB
5. âœ… **å¯è§£é‡Šæ€§**ï¼šåŒå±‚æ³¨æ„åŠ›ç›‘ç£ï¼ˆ$\alpha_{ij}$+$\beta_i$ï¼‰ï¼Œæ³¨æ„åŠ›æƒé‡å¯ç›´æ¥å¯è§†åŒ–
6. âœ… **è®­ç»ƒæµç¨‹æ¸…æ™°**ï¼šä¸‰é˜¶æ®µè®­ç»ƒï¼ˆå†·å¯åŠ¨â†’æ··åˆâ†’è‡ªè®­ç»ƒï¼‰ï¼Œé€»è¾‘è‡ªæ´½
7. âœ… **è‡ªè®­ç»ƒå®‰å…¨**ï¼šåŒè·¯å¾„ç­–ç•¥+é˜¶æ®µåˆ‡æ¢æ¡ä»¶ï¼Œé˜²æ­¢æ¨¡å‹æ¼‚ç§»
8. âœ… **Memoryå¢å¼ºï¼ˆå¯é€‰ï¼‰**ï¼šå¯åœ¨Week 2å¯ç”¨ï¼Œé¢„æœŸAUCæå‡+2-3%

### å±€é™
1. âŒ **è§„åˆ™ç¡¬ç¼–ç **ï¼šæ–°è§„åˆ™éœ€è¦ä¿®æ”¹æŸå¤±å‡½æ•°ï¼ˆä½†å·²æä¾›æ‰©å±•æ¥å£rule_idï¼‰
2. âš ï¸ **é˜ˆå€¼æ•æ„Ÿ**ï¼š$\tau_d$ã€$\tau_v$éœ€è¦é’ˆå¯¹ä¸åŒåœºæ™¯è°ƒæ•´ï¼ˆä½†å·²æä¾›ç½‘æ ¼æœç´¢è®¡åˆ’ï¼‰
3. âš ï¸ **é•¿å°¾åœºæ™¯æ³›åŒ–å¼±**ï¼šä¾èµ–è§„åˆ™å®šä¹‰çš„å®Œå¤‡æ€§ï¼ˆä½†è‡ªè®­ç»ƒStage 3å¯éƒ¨åˆ†ç¼“è§£ï¼‰
4. âŒ **åˆ†æ®µå‡½æ•°çš„ä¸è¿ç»­æ€§**ï¼š$f_{\text{dv}}(d,v)$åœ¨$d=0$å’Œ$d=\tau_d$å¤„ä¸€é˜¶å¯¼æ•°ä¸è¿ç»­ï¼ˆå·¥ç¨‹ä¸Šå¯æ¥å—ï¼Œç†è®ºä¸Šå¯ç”¨smoothå‡½æ•°æ”¹è¿›ï¼‰

### æ”¹è¿›å»ºè®®ï¼ˆITER-02ï¼‰
1. ğŸ”§ å¼•å…¥å¯å­¦ä¹ çš„è§„åˆ™å‚æ•°ï¼ˆ$\tau_d$, $\tau_v$ï¼‰ï¼šä»å›ºå®šé˜ˆå€¼æ”¹ä¸ºå¯å¾®åˆ†å‚æ•°
2. ğŸ”§ ä½¿ç”¨å¹³æ»‘åˆ†æ®µå‡½æ•°ï¼ˆå¦‚soft-plusä»£æ›¿ReLUï¼‰ï¼šæ¶ˆé™¤å¯¼æ•°ä¸è¿ç»­
3. ğŸ”§ è§„åˆ™åº“æ‰©å±•ï¼šæ”¯æŒå¤šè§„åˆ™è”åˆæ£€æµ‹ï¼ˆçº¢ç¯åœ+è½¦é€Ÿ+è½¦é“ï¼‰
4. ğŸ”§ Memory Banké»˜è®¤å¯ç”¨ï¼šåœ¨æ•°æ®é‡å¢åŠ åå¼€å¯

---

# æ–¹æ¡ˆ2ï¼šè®°å¿†å¢å¼ºå¯¹æ¯”å­¦ä¹  + è½¯è§„åˆ™å¼•å¯¼

## 2.1 æ ¸å¿ƒæ€æƒ³
æ„å»º**æ­£å¸¸é©¾é©¶è¡Œä¸ºè®°å¿†åº“**ï¼ˆMemory Bankï¼‰ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ ä½¿æ¨¡å‹å­¦ä¹ æ­£å¸¸æ¨¡å¼çš„åŸå‹è¡¨å¾ã€‚å¼‚å¸¸æ£€æµ‹é€šè¿‡è®¡ç®—æ ·æœ¬ä¸è®°å¿†åº“çš„**é©¬æ°è·ç¦»**å®ç°ã€‚è§„åˆ™ä½œä¸º**è½¯å¼•å¯¼ä¿¡å·**è€Œéç¡¬çº¦æŸï¼Œå¢å¼ºæ¨¡å‹çš„è‡ªé€‚åº”èƒ½åŠ›ã€‚

## 2.2 æ•°å­¦æ¨¡å‹

### 2.2.1 è®°å¿†åº“è®¾è®¡
ç»´æŠ¤å¯å­¦ä¹ çš„è®°å¿†çŸ©é˜µ $\mathbf{M} \in \mathbb{R}^{K \times d_m}$ï¼Œå…¶ä¸­ $K$ ä¸ºè®°å¿†æ§½æ•°é‡ï¼Œ$d_m$ ä¸ºè®°å¿†ç»´åº¦ã€‚

**è®°å¿†åˆå§‹åŒ–**ï¼šé€šè¿‡K-Meansèšç±»æ­£å¸¸æ ·æœ¬çš„ç¼–ç ï¼š
$$
\mathbf{M}^{(0)} = \text{KMeans}\left(\{\mathbf{h}_i^{\text{normal}}\}_{i=1}^{N_{\text{init}}}, K\right)
$$

**è®°å¿†æ£€ç´¢**ï¼šç»™å®šåœºæ™¯ç¼–ç  $\mathbf{h}_i$ï¼Œè®¡ç®—æ³¨æ„åŠ›æƒé‡ï¼š
$$
\begin{aligned}
w_{ik} &= \frac{\exp(\mathbf{h}_i^\top \mathbf{m}_k / \tau)}{\sum_{k'=1}^K \exp(\mathbf{h}_i^\top \mathbf{m}_{k'} / \tau)} \\
\tilde{\mathbf{h}}_i &= \sum_{k=1}^K w_{ik} \mathbf{m}_k \quad \text{(æ£€ç´¢åˆ°çš„è®°å¿†è¡¨å¾)}
\end{aligned}
$$
å…¶ä¸­ $\tau = 0.07$ ä¸ºæ¸©åº¦ç³»æ•°ã€‚

### 2.2.2 å¯¹æ¯”å­¦ä¹ æ¡†æ¶

#### æ­£è´Ÿæ ·æœ¬æ„é€ 
- **æ­£æ ·æœ¬**ï¼šåŒåœºæ™¯çš„ä¸åŒå¢å¼ºè§†å›¾ï¼ˆè£å‰ªã€é®æŒ¡ã€å™ªå£°ï¼‰
- **è´Ÿæ ·æœ¬**ï¼šbatchå†…å…¶ä»–åœºæ™¯ + å†å²é˜Ÿåˆ—æ ·æœ¬

å¯¹æ¯”æŸå¤±ï¼ˆInfoNCEï¼‰ï¼š
$$
\mathcal{L}_{\text{contrast}} = -\log \frac{\exp(\text{sim}(\mathbf{h}_i, \mathbf{h}_i^+) / \tau)}{\exp(\text{sim}(\mathbf{h}_i, \mathbf{h}_i^+) / \tau) + \sum_{j \in \text{neg}} \exp(\text{sim}(\mathbf{h}_i, \mathbf{h}_j^-) / \tau)}
$$

#### è®°å¿†å¯¹æ¯”æŸå¤±
å¼ºåˆ¶æ­£å¸¸æ ·æœ¬ä¸è®°å¿†åº“æ¥è¿‘ï¼Œå¼‚å¸¸æ ·æœ¬è¿œç¦»ï¼š
$$
\mathcal{L}_{\text{mem}} = \begin{cases}
\|\mathbf{h}_i - \tilde{\mathbf{h}}_i\|_2^2, & \text{if } y_i = 0 \text{ (normal)} \\
\max(0, m - \|\mathbf{h}_i - \tilde{\mathbf{h}}_i\|_2)^2, & \text{if } y_i = 1 \text{ (anomaly)}
\end{cases}
$$
å…¶ä¸­ $m = 2.0$ ä¸ºmarginã€‚

### 2.2.3 è½¯è§„åˆ™å¼•å¯¼

è§„åˆ™ä¸ç›´æ¥çº¦æŸæŸå¤±ï¼Œè€Œæ˜¯ä½œä¸º**ä¼ªæ ‡ç­¾ç”Ÿæˆå™¨**ï¼š
$$
\tilde{y}_i = \begin{cases}
\text{normal}, & \text{if } s_i^{\text{rule}} < 0.3 \\
\text{uncertain}, & \text{if } 0.3 \le s_i^{\text{rule}} \le 0.7 \\
\text{anomaly}, & \text{if } s_i^{\text{rule}} > 0.7
\end{cases}
$$

å¯¹äºä¸ç¡®å®šæ ·æœ¬ï¼Œä½¿ç”¨åŠç›‘ç£æŸå¤±ï¼š
$$
\mathcal{L}_{\text{semi}} = -\sum_{i: \tilde{y}_i \neq \text{uncertain}} \left[\tilde{y}_i \log p_i + (1-\tilde{y}_i) \log(1-p_i)\right]
$$

### 2.2.4 å¼‚å¸¸è¯„åˆ†

é©¬æ°è·ç¦»å¼‚å¸¸åˆ†æ•°ï¼š
$$
s_i^{\text{anomaly}} = \sqrt{(\mathbf{h}_i - \tilde{\mathbf{h}}_i)^\top \mathbf{\Sigma}^{-1} (\mathbf{h}_i - \tilde{\mathbf{h}}_i)}
$$
å…¶ä¸­ $\mathbf{\Sigma}$ ä¸ºè®°å¿†åº“çš„åæ–¹å·®çŸ©é˜µï¼ˆåœ¨çº¿ä¼°è®¡ï¼‰ã€‚

## 2.3 è®­ç»ƒç®—æ³•

```python
Algorithm: Memory-Augmented Contrastive Learning

Input:
  - Dataset D (unlabeled scenes)
  - Memory size K, embedding dim d_m
  - Contrastive temperature Ï„
  
Output:
  - Encoder f_Î¸, Memory bank M

1: # Initialize
2: encoder â† GATEncoder(hidden_dim=d_m)
3: memory_bank â† initialize_memory(K, d_m)  # K-Means on normal samples
4: queue â† FIFO(max_size=4096)  # Negative sample queue
5: optimizer â† AdamW([encoder.params, memory_bank], lr=1e-4)
6:
7: for epoch = 1 to E do
8:     for batch (X_b, A_b, entities_b) in DataLoader(D):
9:         # Data augmentation: create two views
10:        (X1, A1), (X2, A2) â† augment(X_b, A_b)
11:        
12:        # Encode both views
13:        H1 â† encoder(X1, A1)  # [B, d_m]
14:        H2 â† encoder(X2, A2)
15:        
16:        # Memory retrieval
17:        W â† softmax(H1 @ memory_bank.T / Ï„)  # [B, K]
18:        H_mem â† W @ memory_bank  # [B, d_m]
19:        
20:        # Compute rule pseudo-labels
21:        rule_scores â† compute_rule_scores(entities_b)
22:        pseudo_labels â† discretize_rule_scores(rule_scores)
23:        
24:        # Contrastive loss (InfoNCE)
25:        logits_pos â† similarity(H1, H2) / Ï„
26:        logits_neg â† similarity(H1, queue) / Ï„
27:        L_contrast â† -log(exp(logits_pos) / (exp(logits_pos) + sum(exp(logits_neg))))
28:        
29:        # Memory contrastive loss
30:        L_mem â† 0
31:        for i in range(B):
32:            if pseudo_labels[i] == 'normal':
33:                L_mem += ||H1[i] - H_mem[i]||^2
34:            elif pseudo_labels[i] == 'anomaly':
35:                L_mem += max(0, margin - ||H1[i] - H_mem[i]||)^2
36:        L_mem â† L_mem / B
37:        
38:        # Semi-supervised loss (only for confident pseudo-labels)
39:        confident_mask â† (pseudo_labels != 'uncertain')
40:        if sum(confident_mask) > 0:
41:            distances â† compute_mahalanobis(H1[confident_mask], H_mem[confident_mask])
42:            probs â† sigmoid(distances)
43:            L_semi â† binary_cross_entropy(probs, pseudo_labels[confident_mask])
44:        else:
45:            L_semi â† 0
46:        
47:        # Total loss
48:        L_total â† L_contrast + Î»_mem * L_mem + Î»_semi * L_semi
49:        
50:        # Backward & update
51:        optimizer.zero_grad()
52:        L_total.backward()
53:        clip_grad_norm_([encoder.params, memory_bank], max_norm=1.0)
54:        optimizer.step()
55:        
56:        # Update negative queue
57:        queue.enqueue(H2.detach())
58:        
59:        # EMA update for memory bank (optional)
60:        if epoch > warmup_epochs:
61:            with torch.no_grad():
62:                memory_bank â† 0.9 * memory_bank + 0.1 * update_memory(H1, pseudo_labels)
63:
64: return encoder, memory_bank
```

## 2.4 ç½‘ç»œæ¶æ„

```python
class MemoryAugmentedDetector(nn.Module):
    def __init__(
        self,
        input_dim: int = 10,
        hidden_dim: int = 256,
        memory_size: int = 512,
        temperature: float = 0.07,
    ):
        super().__init__()
        
        # Encoder (GAT backbone)
        self.encoder = GATEncoder(input_dim, hidden_dim, num_layers=4)
        
        # Memory bank (learnable)
        self.memory_bank = nn.Parameter(torch.randn(memory_size, hidden_dim))
        nn.init.xavier_uniform_(self.memory_bank)
        
        # Projection head for contrastive learning
        self.projection = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, 128)
        )
        
        # Anomaly scoring head
        self.score_head = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, 1)
        )
        
        self.temperature = temperature
        self.register_buffer('cov_matrix', torch.eye(hidden_dim))
    
    def retrieve_memory(self, h: Tensor) -> Tuple[Tensor, Tensor]:
        """Memory retrieval with attention"""
        # h: [B, hidden_dim]
        sim = F.cosine_similarity(
            h.unsqueeze(1),              # [B, 1, hidden_dim]
            self.memory_bank.unsqueeze(0),  # [1, K, hidden_dim]
            dim=-1
        )  # [B, K]
        
        weights = F.softmax(sim / self.temperature, dim=-1)
        h_mem = torch.matmul(weights, self.memory_bank)  # [B, hidden_dim]
        
        return h_mem, weights
    
    def compute_anomaly_score(self, h: Tensor, h_mem: Tensor) -> Tensor:
        """Mahalanobis distance-based scoring"""
        diff = h - h_mem  # [B, hidden_dim]
        
        # Mahalanobis distance
        inv_cov = torch.inverse(self.cov_matrix + 1e-6 * torch.eye(h.size(1), device=h.device))
        mahal_dist = torch.sqrt(torch.sum(diff @ inv_cov * diff, dim=-1))
        
        return torch.sigmoid(mahal_dist)
    
    def forward(self, x: Tensor, edge_index: Tensor, return_embeddings: bool = False):
        # Encode scene
        h = self.encoder(x, edge_index)  # [N, hidden_dim]
        
        # Pool to scene-level (mean pooling for simplicity)
        h_scene = h.mean(dim=0, keepdim=True)  # [1, hidden_dim]
        
        # Retrieve memory
        h_mem, mem_weights = self.retrieve_memory(h_scene)
        
        # Anomaly scoring
        score = self.compute_anomaly_score(h_scene, h_mem)
        
        if return_embeddings:
            return score, h_scene, h_mem, mem_weights
        return score
    
    def update_covariance(self, embeddings: Tensor):
        """Online covariance estimation"""
        with torch.no_grad():
            cov = torch.cov(embeddings.T)
            self.cov_matrix = 0.9 * self.cov_matrix + 0.1 * cov
```

## 2.5 ä¼˜åŠ¿ä¸å±€é™

### ä¼˜åŠ¿
1. âœ… **è‡ªé€‚åº”æ€§å¼º**ï¼šè®°å¿†åº“å¯éšæ•°æ®åˆ†å¸ƒæ¼”åŒ–
2. âœ… **è§„åˆ™è§£è€¦**ï¼šä¸ä¾èµ–æ˜¾å¼è§„åˆ™ï¼Œé€‚åˆå¤æ‚åœºæ™¯
3. âœ… **å°‘æ ·æœ¬å­¦ä¹ **ï¼šå¯¹æ¯”å­¦ä¹ åœ¨å°æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜äºç›‘ç£å­¦ä¹ 
4. âœ… **å¯è§£é‡Šæ€§**ï¼šè®°å¿†æ£€ç´¢æƒé‡æä¾›å†³ç­–ä¾æ®

### å±€é™
1. âŒ **è®­ç»ƒå¤æ‚**ï¼šå¯¹æ¯”å­¦ä¹ éœ€è¦ç²¾å¿ƒè®¾è®¡æ•°æ®å¢å¼º
2. âŒ **è®¡ç®—å¼€é”€å¤§**ï¼šè®°å¿†æ£€ç´¢ + åæ–¹å·®ä¼°è®¡å¢åŠ æ¨ç†æ—¶é—´
3. âŒ **å†·å¯åŠ¨é—®é¢˜**ï¼šè®°å¿†åº“åˆå§‹åŒ–éœ€è¦è¶³å¤Ÿçš„æ­£å¸¸æ ·æœ¬

---

# æ–¹æ¡ˆ3ï¼šå› æœå›¾ç½‘ç»œ + åäº‹å®æ¨ç†ï¼ˆCausal GNN + Counterfactual Explanationï¼‰

## 3.1 æ ¸å¿ƒæ€æƒ³
å°†äº¤é€šåœºæ™¯å»ºæ¨¡ä¸º**å› æœå›¾**ï¼Œæ˜¾å¼å»ºæ¨¡å®ä½“é—´çš„å› æœå…³ç³»ï¼ˆå¦‚"çº¢ç¯ â†’ è½¦è¾†åº”åœæ­¢"ï¼‰ã€‚é€šè¿‡**ç»“æ„å› æœæ¨¡å‹ï¼ˆSCMï¼‰**å­¦ä¹ å› æœæœºåˆ¶ï¼Œå¼‚å¸¸æ£€æµ‹ç­‰ä»·äºå› æœè¿èƒŒæ£€æµ‹ã€‚å¯è§£é‡Šæ€§é€šè¿‡**åäº‹å®æ¨ç†**å®ç°ï¼š"å¦‚æœç¯æ˜¯ç»¿è‰²ï¼Œè½¦è¾†ä¼šé€šè¿‡å—ï¼Ÿ"

## 3.2 æ•°å­¦æ¨¡å‹

### 3.2.1 ç»“æ„å› æœæ¨¡å‹ï¼ˆSCMï¼‰

å®šä¹‰å› æœå˜é‡ï¼š
- $L \in \{\text{red, yellow, green}\}$ï¼šäº¤é€šç¯çŠ¶æ€
- $D \in \mathbb{R}_+$ï¼šè½¦è¾†åˆ°åœæ­¢çº¿è·ç¦»
- $V \in \mathbb{R}_+$ï¼šè½¦è¾†é€Ÿåº¦
- $A \in \{0,1\}$ï¼šè½¦è¾†è¡Œä¸ºï¼ˆ0=åœæ­¢ï¼Œ1=é€šè¿‡ï¼‰

å› æœå›¾ç»“æ„ï¼š
$$
L \rightarrow A \leftarrow D \leftarrow V
$$

ç»“æ„æ–¹ç¨‹ï¼š
$$
\begin{aligned}
L &\sim \text{Categorical}([0.5, 0.1, 0.4]) \quad \text{(å¤–ç”Ÿå˜é‡)} \\
V &\sim \mathcal{N}(\mu_v, \sigma_v^2) \\
D &= f_D(V, U_D), \quad U_D \sim \mathcal{N}(0, \sigma_D^2) \\
A &= f_A(L, D, U_A), \quad U_A \sim \mathcal{N}(0, \sigma_A^2)
\end{aligned}
$$

å…¶ä¸­ $f_A$ æ˜¯å¯å­¦ä¹ çš„å› æœæœºåˆ¶ï¼ˆç¥ç»ç½‘ç»œï¼‰ï¼š
$$
f_A(L, D) = \sigma\left(\mathbf{w}_L^\top \text{onehot}(L) + \mathbf{w}_D \cdot D + b\right)
$$

### 3.2.2 å› æœå›¾ç¥ç»ç½‘ç»œ

#### å› æœé‚»æ¥çŸ©é˜µ
ä¸åŒäºä¼ ç»ŸGNNçš„å¯¹ç§°é‚»æ¥çŸ©é˜µï¼Œå› æœå›¾ä½¿ç”¨**æœ‰å‘é‚»æ¥çŸ©é˜µ** $\mathbf{A}_{\text{causal}}$ï¼Œå…ƒç´  $A_{ij}=1$ å½“ä¸”ä»…å½“ $v_i$ æ˜¯ $v_j$ çš„å› æœçˆ¶èŠ‚ç‚¹ã€‚

#### å› æœæ¶ˆæ¯ä¼ é€’
$$
\begin{aligned}
\mathbf{m}_{i \rightarrow j} &= \phi_{\text{cause}}\left(\mathbf{h}_i, \mathbf{h}_j, \mathbf{e}_{ij}\right) \quad \text{if } A_{\text{causal}, ij} = 1 \\
\mathbf{h}_j^{(l+1)} &= \psi_{\text{effect}}\left(\mathbf{h}_j^{(l)}, \sum_{i \in \text{Parents}(j)} \mathbf{m}_{i \rightarrow j}\right)
\end{aligned}
$$

å…¶ä¸­ $\phi_{\text{cause}}$ å’Œ $\psi_{\text{effect}}$ æ˜¯å¯å­¦ä¹ çš„ç¥ç»ç½‘ç»œã€‚

### 3.2.3 åäº‹å®æ¨ç†

ç»™å®šè§‚æµ‹ $(L=\text{red}, D=3m, V=5m/s, A=1)$ï¼ˆé—¯çº¢ç¯ï¼‰ï¼Œè®¡ç®—åäº‹å®ï¼š

**å¹²é¢„ï¼ˆInterventionï¼‰**ï¼šå¼ºåˆ¶ $\text{do}(L=\text{green})$ï¼Œé‡æ–°è®¡ç®—ï¼š
$$
A_{\text{cf}} = f_A(\text{green}, D, U_A) = \sigma(\mathbf{w}_L^\top [0,0,1] + \mathbf{w}_D \cdot 3 + b)
$$

**åäº‹å®è§£é‡Š**ï¼š
$$
\text{Explanation} = \begin{cases}
\text{"å› æœè¿èƒŒï¼šçº¢ç¯åº”åœæ­¢"}, & \text{if } A_{\text{cf}} = 0 \land A_{\text{obs}} = 1 \\
\text{"æ­£å¸¸è¡Œä¸º"}, & \text{otherwise}
\end{cases}
$$

### 3.2.4 å¼‚å¸¸æ£€æµ‹æŸå¤±

$$
\begin{aligned}
\mathcal{L}_{\text{causal}} &= \mathcal{L}_{\text{NLL}} + \lambda_1 \mathcal{L}_{\text{DAG}} + \lambda_2 \mathcal{L}_{\text{CF}} \\
\\
\mathcal{L}_{\text{NLL}} &= -\sum_{i=1}^N \log p(A_i | \text{Parents}(A_i)) \\
\\
\mathcal{L}_{\text{DAG}} &= \text{trace}(\mathbf{e}^{\mathbf{A} \circ \mathbf{A}}) - d \quad \text{(æ— ç¯çº¦æŸ)} \\
\\
\mathcal{L}_{\text{CF}} &= \sum_{i=1}^N \left\|A_i^{\text{obs}} - A_i^{\text{cf}}(\text{do}(L_i=\text{normal}))\right\|^2
\end{aligned}
$$

å…¶ä¸­ $\mathcal{L}_{\text{DAG}}$ ä¿è¯å› æœå›¾æ— ç¯ï¼ˆZheng et al., 2018ï¼‰ã€‚

## 3.3 è®­ç»ƒç®—æ³•

```python
Algorithm: Causal GNN with Counterfactual Learning

Input:
  - Dataset D = {(X_i, A_i, entities_i)}
  - Causal graph structure prior G_prior
  
Output:
  - Causal model Î¸_causal
  
1: # Initialize causal adjacency matrix
2: A_causal â† initialize_from_prior(G_prior)  # e.g., Lâ†’A, Dâ†’A
3: A_causal â† make_learnable(A_causal)
4:
5: # Initialize causal mechanisms
6: f_A â† CausalMLP(input_dim=num_parents)
7: optimizer â† AdamW([A_causal, f_A.params], lr=1e-3)
8:
9: for epoch = 1 to E do
10:    for batch (X, entities, actions) in DataLoader(D):
11:        # Extract causal variables
12:        L â† extract_light_state(entities)  # [B]
13:        D â† extract_distance(entities)     # [B]
14:        V â† extract_velocity(entities)     # [B]
15:        A_obs â† actions                    # [B]
16:        
17:        # Forward: predict action from causal parents
18:        parents_feat â† concat([onehot(L), D, V])  # [B, d_parents]
19:        A_pred â† f_A(parents_feat)  # [B]
20:        
21:        # Loss 1: Negative log-likelihood
22:        L_NLL â† binary_cross_entropy(A_pred, A_obs)
23:        
24:        # Loss 2: DAG constraint (acyclicity)
25:        A_squared â† A_causal @ A_causal
26:        L_DAG â† trace(exp(A_squared)) - d
27:        
28:        # Loss 3: Counterfactual consistency
29:        L_CF â† 0
30:        for i in range(B):
31:            if L[i] == 'red' and A_obs[i] == 1:  # Violation observed
32:                # Intervene: do(L='green')
33:                L_cf â† 'green'
34:                parents_cf â† concat([onehot(L_cf), D[i], V[i]])
35:                A_cf â† f_A(parents_cf)
36:                
37:                # Counterfactual should predict "pass"
38:                L_CF += (A_cf - 1)^2
39:        L_CF â† L_CF / B
40:        
41:        # Total loss
42:        L_total â† L_NLL + Î»_1 * L_DAG + Î»_2 * L_CF
43:        
44:        # Backward
45:        optimizer.zero_grad()
46:        L_total.backward()
47:        
48:        # Project A_causal to valid DAG space
49:        with torch.no_grad():
50:            A_causal â† threshold(A_causal, min=0, max=1)
51:            A_causal â† A_causal * (1 - eye(d))  # Remove self-loops
52:        
53:        optimizer.step()
54:    
55:    # Validate causal graph
56:    if epoch % 10 == 0:
57:        is_dag â† check_acyclic(A_causal)
58:        if not is_dag:
59:            warn("Causal graph not DAG, applying projection")
60:            A_causal â† project_to_dag(A_causal)
61:
62: return f_A, A_causal
```

## 3.4 åäº‹å®è§£é‡Šç”Ÿæˆ

```python
Algorithm: Counterfactual Explanation Generation

Input:
  - Observed scene: (L_obs, D_obs, V_obs, A_obs)
  - Causal model: f_A, A_causal
  
Output:
  - Explanation with counterfactual scenarios

1: # Check if violation occurred
2: if not is_violation(L_obs, D_obs, V_obs, A_obs):
3:     return "Normal behavior, no explanation needed"
4:
5: explanations â† []
6:
7: # Counterfactual 1: What if light was green?
8: if L_obs == 'red':
9:     A_cf1 â† f_A(onehot('green'), D_obs, V_obs)
10:    explanation_1 â† {
11:        'type': 'intervention_light',
12:        'intervention': 'do(Light=green)',
13:        'predicted_action': 'pass' if A_cf1 > 0.5 else 'stop',
14:        'consistency': 'violated' if A_cf1 > 0.5 else 'maintained',
15:        'message': f"If light was green, vehicle would {'pass' if A_cf1 > 0.5 else 'stop'}"
16:    }
17:    explanations.append(explanation_1)
18:
19: # Counterfactual 2: What if distance was larger?
20: D_cf2 â† D_obs + 20  # Add 20m
21: A_cf2 â† f_A(onehot(L_obs), D_cf2, V_obs)
22: explanation_2 â† {
23:     'type': 'intervention_distance',
24:     'intervention': f'do(Distance={D_cf2}m)',
25:     'predicted_action': 'pass' if A_cf2 > 0.5 else 'stop',
26:     'message': f"If vehicle was {D_cf2}m away, it would {'pass' if A_cf2 > 0.5 else 'stop'}"
27: }
28: explanations.append(explanation_2)
29:
30: # Counterfactual 3: What if velocity was zero?
31: A_cf3 â† f_A(onehot(L_obs), D_obs, V_cf=0)
32: explanation_3 â† {
33:     'type': 'intervention_velocity',
34:     'intervention': 'do(Velocity=0)',
35:     'predicted_action': 'stop',
36:     'message': "Stopping would comply with red light rule"
37: }
38: explanations.append(explanation_3)
39:
40: # Generate causal attribution
41: attribution â† compute_shapley_values(f_A, [L_obs, D_obs, V_obs])
42: explanations.append({
43:     'type': 'attribution',
44:     'light_contribution': attribution[0],
45:     'distance_contribution': attribution[1],
46:     'velocity_contribution': attribution[2],
47:     'message': f"Primary cause: {argmax(attribution)}"
48: })
49:
50: return format_explanation(explanations)
```

## 3.5 ç½‘ç»œæ¶æ„

```python
class CausalGNN(nn.Module):
    def __init__(
        self,
        num_vars: int = 4,  # L, D, V, A
        hidden_dim: int = 64,
        num_layers: int = 3,
    ):
        super().__init__()
        
        # Learnable causal adjacency matrix
        self.causal_adj = nn.Parameter(torch.zeros(num_vars, num_vars))
        
        # Initialize with prior knowledge
        # L(0) â†’ A(3), D(1) â†’ A(3), V(2) â†’ D(1), V(2) â†’ A(3)
        with torch.no_grad():
            self.causal_adj[0, 3] = 1.0  # L â†’ A
            self.causal_adj[1, 3] = 1.0  # D â†’ A
            self.causal_adj[2, 1] = 1.0  # V â†’ D
            self.causal_adj[2, 3] = 1.0  # V â†’ A
        
        # Causal mechanisms (one per variable)
        self.mechanisms = nn.ModuleDict({
            'distance': nn.Sequential(  # D = f(V)
                nn.Linear(1, hidden_dim),
                nn.ReLU(),
                nn.Linear(hidden_dim, 1)
            ),
            'action': nn.Sequential(  # A = f(L, D, V)
                nn.Linear(3 + 1 + 1, hidden_dim),  # 3 for L (one-hot), 1 for D, 1 for V
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(hidden_dim, hidden_dim // 2),
                nn.ReLU(),
                nn.Linear(hidden_dim // 2, 1),
                nn.Sigmoid()
            )
        })
    
    def forward(self, light, distance, velocity):
        """
        Args:
            light: [B, 3] one-hot encoded
            distance: [B, 1]
            velocity: [B, 1]
        Returns:
            action_prob: [B, 1]
        """
        # Predict action from causal parents
        parents = torch.cat([light, distance, velocity], dim=-1)
        action_prob = self.mechanisms['action'](parents)
        return action_prob
    
    def intervene(self, light, distance, velocity, intervention):
        """
        Perform do-calculus intervention
        
        Args:
            intervention: dict, e.g., {'light': tensor([0, 0, 1])} for do(L=green)
        """
        if 'light' in intervention:
            light = intervention['light']
        if 'distance' in intervention:
            distance = intervention['distance']
        if 'velocity' in intervention:
            velocity = intervention['velocity']
        
        return self.forward(light, distance, velocity)
    
    def dag_penalty(self):
        """Compute DAG constraint: h(A) = tr(e^(Aâ—¦A)) - d"""
        adj_squared = torch.matmul(self.causal_adj, self.causal_adj)
        return torch.trace(torch.matrix_exp(adj_squared)) - self.causal_adj.size(0)
    
    def get_causal_graph(self):
        """Extract binary causal graph"""
        with torch.no_grad():
            return (torch.sigmoid(self.causal_adj) > 0.5).float()
```

## 3.6 ä¼˜åŠ¿ä¸å±€é™

### ä¼˜åŠ¿
1. âœ… **æœ€å¼ºå¯è§£é‡Šæ€§**ï¼šåäº‹å®æ¨ç†æä¾›"why"å’Œ"what-if"ç­”æ¡ˆ
2. âœ… **å› æœæ³›åŒ–**ï¼šå­¦åˆ°çš„å› æœæœºåˆ¶å¯è¿ç§»åˆ°æ–°åœºæ™¯
3. âœ… **è§„åˆ™è‡ªåŠ¨å‘ç°**ï¼šæ— éœ€æ‰‹å·¥ç¼–å†™è§„åˆ™ï¼Œä»æ•°æ®ä¸­å­¦ä¹ å› æœå…³ç³»
4. âœ… **å­¦æœ¯ä»·å€¼é«˜**ï¼šå› æœæ¨ç†æ˜¯AIå¯è§£é‡Šæ€§çš„å‰æ²¿æ–¹å‘

### å±€é™
1. âŒ **æé«˜å¤æ‚åº¦**ï¼šå› æœå‘ç°ã€DAGçº¦æŸã€åäº‹å®è®¡ç®—å‡ä¸ºNPéš¾é—®é¢˜
2. âŒ **æ•°æ®éœ€æ±‚å¤§**ï¼šéœ€è¦ä¸°å¯Œçš„å¹²é¢„æ•°æ®ï¼ˆæˆ–å¼ºå…ˆéªŒï¼‰æ‰èƒ½å­¦åˆ°æ­£ç¡®å› æœå›¾
3. âŒ **è®­ç»ƒä¸ç¨³å®š**ï¼šDAGçº¦æŸéš¾ä»¥ä¼˜åŒ–ï¼Œæ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜
4. âŒ **å·¥ç¨‹åŒ–å›°éš¾**ï¼šç°æœ‰å› æœæ¨ç†åº“ï¼ˆå¦‚DoWhyï¼‰ä¸æ·±åº¦å­¦ä¹ æ¡†æ¶é›†æˆä¸ä½³

---

# ç»¼åˆè¯„ä¼°ä¸å»ºè®®

## å¯¹æ¯”åˆ†æ

| è¯„ä¼°ç»´åº¦ | æ–¹æ¡ˆ1ï¼ˆGAT+ç¡¬çº¦æŸï¼‰ | æ–¹æ¡ˆ2ï¼ˆè®°å¿†å¯¹æ¯”ï¼‰ | æ–¹æ¡ˆ3ï¼ˆå› æœæ¨ç†ï¼‰ |
|---------|---------|---------|---------|
| **MVPäº¤ä»˜é€Ÿåº¦** | â­â­â­â­â­ 1-2å‘¨ | â­â­â­ 3-4å‘¨ | â­â­ 6-8å‘¨ |
| **ä»£ç å¤æ‚åº¦** | ~1200 LOC | ~2000 LOC | ~3500 LOC |
| **è®ºæ–‡ä»·å€¼** | â­â­ å·¥ç¨‹å®ç° | â­â­â­â­ åˆ›æ–°æ–¹æ³• | â­â­â­â­â­ é¡¶ä¼šæ°´å¹³ |
| **å¯ç»´æŠ¤æ€§** | â­â­â­â­ æ¨¡å—æ¸…æ™° | â­â­â­ ä¾èµ–å¯¹æ¯”å­¦ä¹ æ¡†æ¶ | â­â­ å› æœå›¾ç»´æŠ¤æˆæœ¬é«˜ |
| **æ‰©å±•åˆ°å¤šè§„åˆ™** | â­â­â­ éœ€é€ä¸ªç¼–å†™æŸå¤± | â­â­â­â­ è®°å¿†åº“è‡ªé€‚åº” | â­â­â­â­â­ è‡ªåŠ¨å› æœå‘ç° |
| **å®é™…éƒ¨ç½²éš¾åº¦** | â­â­ æ˜“äºéƒ¨ç½² | â­â­â­ éœ€ç»´æŠ¤è®°å¿†åº“ | â­â­â­â­ æ¨ç†å¼€é”€å¤§ |

## æ¨èæ–¹æ¡ˆ

### âœ… **ç«‹å³æ‰§è¡Œï¼šæ–¹æ¡ˆ1ï¼ˆå¤šé˜¶æ®µæ³¨æ„åŠ›GAT + ç¡¬çº¦æŸï¼‰**
**ç†ç”±**ï¼š
1. æ»¡è¶³MVPæ—¶é—´è¦æ±‚ï¼ˆ12-15äº¤ä»˜ï¼‰
2. å·¥ç¨‹é£é™©æœ€ä½ï¼ŒåŸºäºæˆç†Ÿçš„GATæ¶æ„
3. å¯è§£é‡Šæ€§è¾¾æ ‡ï¼ˆæ³¨æ„åŠ›æƒé‡å¯è§†åŒ–ï¼‰
4. è§„åˆ™çº¦æŸä¿è¯ç¬¦åˆäº¤é€šæ³•è§„

**å®æ–½å»ºè®®**ï¼š
- ä¼˜å…ˆå®ç°3å±‚GAT + è§„åˆ™æŸå¤±
- ç¬¬2é˜¶æ®µï¼ˆå…¨å±€æ³¨æ„åŠ›ï¼‰å’Œç¬¬3é˜¶æ®µï¼ˆè§„åˆ™èšç„¦ï¼‰å¯æ¸è¿›å¼å¼€å‘
- ä½¿ç”¨PyTorch GeometricåŠ é€Ÿå®ç°

### ğŸ“‹ **ITER-02è§„åˆ’ï¼šæ–¹æ¡ˆ2ï¼ˆè®°å¿†å¢å¼ºå¯¹æ¯”å­¦ä¹ ï¼‰**
**ç†ç”±**ï¼š
1. æ•°æ®é‡å¢åŠ åæ€§èƒ½æ›´ä¼˜
2. å‡å°‘å¯¹æ‰‹å·¥è§„åˆ™çš„ä¾èµ–
3. å¯ä½œä¸ºæ–¹æ¡ˆ1çš„å‡çº§è·¯å¾„ï¼ˆä¿ç•™GAT backboneï¼Œå¢åŠ è®°å¿†æ¨¡å—ï¼‰

**å®æ–½å»ºè®®**ï¼š
- åœ¨æ–¹æ¡ˆ1åŸºç¡€ä¸Šå¢åŠ è®°å¿†åº“æ¨¡å—
- ä½¿ç”¨MoCo v3æ¡†æ¶ç®€åŒ–å¯¹æ¯”å­¦ä¹ å®ç°
- è®°å¿†åº“ä¸è§„åˆ™çº¦æŸå¹¶è¡Œï¼Œå½¢æˆæ··åˆæ–¹æ¡ˆ

### ğŸ”¬ **è®ºæ–‡æ–¹å‘ï¼šæ–¹æ¡ˆ3ï¼ˆå› æœå›¾ç½‘ç»œï¼‰**
**ç†ç”±**ï¼š
1. å­¦æœ¯åˆ›æ–°æ€§æœ€é«˜ï¼Œé€‚åˆå‘è¡¨
2. å¯ä½œä¸ºé•¿æœŸç ”ç©¶æ–¹å‘
3. ä¸æ–¹æ¡ˆ1/2ä¸å†²çªï¼Œå¯å¹¶è¡Œæ¢ç´¢

**å®æ–½å»ºè®®**ï¼š
- ä½œä¸ºç ”ç©¶å‹ä»»åŠ¡ï¼Œä¸çº³å…¥MVPäº¤ä»˜
- å¯åœ¨ITER-03æˆ–åç»­è¿­ä»£ä¸­å®éªŒ
- å»ºè®®å…ˆé˜…è¯»å› æœå‘ç°æ–‡çŒ®ï¼ˆZheng et al., 2018; Ke et al., 2019ï¼‰

---

## ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç«‹å³å†³ç­–**ï¼šé€‰å®šæ–¹æ¡ˆ1ä½œä¸ºMVPå®ç°è·¯å¾„
2. **æ›´æ–°è®¾è®¡æ–‡æ¡£**ï¼šå°†æ–¹æ¡ˆ1çš„è¯¦ç»†è®¾è®¡åˆå¹¶åˆ° `Design-ITER-2025-01.md`
3. **å¯åŠ¨å¼€å‘**ï¼šæŒ‰ç…§ç®—æ³•ä¼ªä»£ç å®ç° `MultiStageAttentionGAT` ç±»
4. **å‡†å¤‡æ•°æ®**ï¼šæ‰§è¡Œ `scripts/prepare_synthetic_data.py` ç”Ÿæˆè®­ç»ƒæ•°æ®
5. **å»ºç«‹åŸºçº¿**ï¼šå…ˆå®ç°ç®€åŒ–ç‰ˆï¼ˆå•å±‚GAT + è§„åˆ™æŸå¤±ï¼‰ï¼ŒéªŒè¯æµç¨‹

---

## å‚è€ƒæ–‡çŒ®

1. VeliÄkoviÄ‡ et al. (2018). "Graph Attention Networks." ICLR.
2. Chen et al. (2020). "A Simple Framework for Contrastive Learning of Visual Representations." ICML.
3. Zheng et al. (2018). "DAGs with NO TEARS: Continuous Optimization for Structure Learning." NeurIPS.
4. SchÃ¶lkopf et al. (2021). "Toward Causal Representation Learning." Proceedings of the IEEE.
5. Gong et al. (2022). "Memory-augmented Graph Neural Networks." AAAI.

---

## Checklist

- [x] æä¾›3ç§å®Œæ•´ç®—æ³•æ–¹æ¡ˆ
- [x] åŒ…å«æ•°å­¦å…¬å¼ä¸æ¨å¯¼
- [x] æä¾›ä¼ªä»£ç ä¸ç½‘ç»œæ¶æ„
- [x] ç»™å‡ºä¼˜åŠ£åŠ¿å¯¹æ¯”
- [x] æ˜ç¡®æ¨èæ–¹æ¡ˆä¸å®æ–½è·¯å¾„
- [ ] è¯„å®¡äººç­¾å­—ï¼ˆå¾…è¯„å®¡ï¼‰


